---
title: "TimeToEventData"
output: html_document
date: "2024-05-08"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Background
In the manuscript, "Quantifying repeatability or inter-class correlation from time-to-event data: Towards a standardized approach" we describe a method to quantify repeatability from time-to-event data. In this supplementary materials page we demonstrate the use of this method with real data in 3 worked examples. We additionally provide the data and code used in the case study section of the manuscript. Lastly, we present the methods and results for a simulation study to illustrate the relationship among ICC (repeatability) values derived from 4 different models and residual variance estimators.

## Worked Examples
Behavior data range widely in the number of individuals as well as the number of repeated measures on each individual. Furthermore, the presence and amount of censored data can vary. We use openly available data to present 3 worked examples that span a range of sample sizes and amount of censoring.

### Example 1: Frog aggression towards a simulated intruder
Our first example data set is from Peignier et al. 2022. They investigated whether *A. femoralis* frogs show repeatable aggressive behavior by measuring the latency of territorial males to approach a simulated intruder. There sample size included 51 males with 3.2 +/- 1.31 trials each. Censored data are present (6% of trials) because some males did not approach the simulated intruder. These individuals were given a ceiling value of 300 seconds (the longest trial time). The authors log-transformed this variable and used the Gaussian family in the rpt function (Stoffel et al. 2017).

In this first worked example, we give a high level of detail on the methods and model types described in the paper. In the subsequent examples, we present the data and run the analysis showing fewer of the intermediary or alternative steps.

```{r E1 - load the data, echo=FALSE}
library(coxme)
library(survival)
library(here)

# Data from Peignier et al. 2022
fdata = read.csv(here("data", "Frog_personality.csv"))
fdata = fdata[which(fdata$sex == "m"),c(1,2,9)] # Only males participated in the aggression test, we only need columns for ID, repetition and latency to approach the simulated intruder. Authors did not include fixed effects, so we won't either.
fdata = fdata[!is.na(fdata$jump_s),] # Unclear what the NAs represent, but the authors remove these data, so we will too.
fdata$event = ifelse(fdata$jump_s==300, 0,1) # Create event column that indicates whether the data were censored for that trial.

head(fdata,20)
```

This is a classic (un-exploded) format for animal personality data. We will first conduct a Cox proportional hazards model using the coxme package in R (Therneau, 2022). The coxme function is able to estimate multiple random effects, as well as random slopes. We included a random effect for individual identity as in Equation 3 of the main text, except that there are no fixed effects in this frog model. In this model specification, the response variable is a "survival" object that combines latency to jump ("jump_s") and the event indicator.
```{r E1 - coxme continuous model, echo = F}
c1 = coxme(Surv(jump_s,event)~1+(1|ID), data = fdata)

var <- VarCorr(c1)$ID[[1]] # Random effect variance is 0.40
```


However, we need a data set that includes discrete time intervals to show the equivalence in time-to-event ICC values between Cox proportional hazards models and binomial GLMM. This is referred to as an "exploded" data set and we can use the function survSplit in the survival package (Therneau, 2024) to easily transform the data. How to choose interval size... (fill in based on simulation results)

```{r E1 - explode the data, echo=F}
# decide on the intervals
psych::describe(fdata$jump_s)

fdata_int = survSplit(Surv(jump_s,event) ~ repetition+ID, data = fdata, 
                      cut = c(50,100,150,200,250), start = "tstart",end = "tstop")

head(fdata_int,20)
```

Now we can compare the basic Cox model with the model using the exploded data set. The response variable is again a "survival" object, but now combines the start and stop time of the interval and the event indicator. 
```{r E1 - coxme interval model, echo = F}
c1_int = coxme(Surv(tstart,tstop,event)~1+(1|ID), data = fdata_int)

var <- VarCorr(c1_int)$ID[[1]] # Random effect variance is 0.40
```

You can see that the variance estimate for the random effect is the same in both Cox models.

We can now estimate the ICC using Equation 7 from the main text. Because of the equivalence of mixed-effects Cox models with binomial generalized linear mixed-effects models with the clog-log link (see below), Equation 7 uses the random effect variance from the Cox model and the binomial GLMM distribution-specific residual variance estimator. 
```{r E1 - Parametric ICC calculation, echo = F}
var/(var + pi^2/6)
# 0.19
# Original paper reports a repeatabiltiy of 0.24 (CI: 0.07-0.40)

```
This yields an ICC value of 0.19.

In Equation 5 of the main text we show the calculation for the non-parametric version of the ICC, Kendall's tau, which assumes a Gamma distribution of the random effect. Additionally, it is not feasible to estimate the non-parametric ICC when there are more than one random effect. We wrote a function to obtain the non-parametric ICC numerically:
```{r E1 - Non-parametric ICC function, echo = F}
# function obtained from
# https://github.com/cran/parfm/blob/master/R/frailtydistros.R

g <- function(w, k, s, sigma2) {
  -k * w + exp(w) * s + w ^ 2 /  (2 * sigma2)
}

g1 <- function(w, k, s, sigma2) {
  -k + exp(w) * s + w / sigma2
}

g2 <- function(w, k, s, sigma2) {
  exp(w) * s + 1 / sigma2    
} 

Lapl <- Vectorize(function(s, k, sigma2) {
  # Find wTilde = max(g(w)) so that g'(wTilde; k, s, theta) = 0
  WARN <- getOption("warn")
  options(warn = -1)
  wTilde <- optimize(f = g, c(-1e10, 1e10), maximum = FALSE,
                     k = k, s = s, sigma2 = sigma2)$minimum
  options(warn = WARN)
  
  # Approximate the integral via Laplacian method
  res <- (-1) ^ k * 
    exp(-g(w = wTilde, k = k, s = s, sigma2 = sigma2)) /
    sqrt(sigma2 * g2(w = wTilde, k = k, s = s, sigma2 = sigma2))
  return(res)
}, 's')

intTau <- Vectorize(function(x, intTau.sigma2=sigma2) {
  res <- x * 
    Lapl(s = x, k = 0, sigma2 = intTau.sigma2) *
    Lapl(s = x, k = 2, sigma2 = intTau.sigma2)
  return(res)
}, "x")

fr.lognormal <- function(k,
                         s,
                         sigma2,
                         what = "logLT") {
  # if (!(is.numeric(sigma2) && (sigma2 > 0)))
  # stop("The parameter sigma2 is not a positive value.")
  
  if (what == "logLT") {
    # if (!(is.numeric(s) && (s > 0)))
    #     stop("The parameter s is not positive.")
    # Find wTilde = max(g(w)) so that g'(wTilde; k, s, theta) = 0
    WARN <- getOption("warn")
    options(warn = -1)
    wTilde <- nlm(f = g, p = 0, k = k, s = s, sigma2 = sigma2)$estimate
    options(warn = WARN)
    
    # Approximate the integral via Laplacian method
    res <- -g(w = wTilde, k = k, s = s, sigma2 = sigma2) -
      log(sigma2 * g2(w = wTilde, k = k, s = s, sigma2 = sigma2)
      ) / 2
    return(res)
  }
  else if (what == "tau") {
    intTau <- Vectorize(function(x, intTau.sigma2=sigma2) {
      res <- x * 
        Lapl(s = x, k = 0, sigma2 = intTau.sigma2) *
        Lapl(s = x, k = 2, sigma2 = intTau.sigma2)
      return(res)
    }, "x")
    
    tauRes <- 4 * integrate(
      f = intTau, lower = 0, upper = Inf, 
      intTau.sigma2 = sigma2)$value - 1
    return(tauRes)
  }
}

```

```{r E1 - Non-parametric ICC estimate, echo=, warning=FALSE}
fr.lognormal(k,s,var,what = "tau")
```
The non-parametric ICC estimate for these frog data is 0.16.

We now demonstrate the use of the binomial GLMM to analyze the discrete time interval survival data. We use the interval data that we created above (fdata_int). However, we also need to include a column identifying the time interval to include as a fixed effect, which takes the place of the start and stop time from the Cox models.
```{r E1 - binomial GLMM}
# we previously told the survSplit function to create intervals every 50 seconds.
# create column to identify intervals
fdata_int$interval = NA
fdata_int$interval =  ifelse(fdata_int$tstart == 0,1,fdata_int$interval)
fdata_int$interval =  ifelse(fdata_int$tstart == 50,2,fdata_int$interval)
fdata_int$interval =  ifelse(fdata_int$tstart == 100,3,fdata_int$interval)
fdata_int$interval =  ifelse(fdata_int$tstart == 150,4,fdata_int$interval)
fdata_int$interval =  ifelse(fdata_int$tstart == 200,5,fdata_int$interval)
fdata_int$interval =  ifelse(fdata_int$tstart == 250,6,fdata_int$interval)

# Run the binomial glmm model
library(lme4)
b1 <- glmer(event ~ as.factor(interval) + (1|ID), data=fdata_int,
                 family = binomial(link="cloglog"), nAGQ=7)
var <- b1@theta^2
var/(var + pi^2/6)

```
The random effect variance from the binomial GLMM is 0.46, and the ICC value using Equation 7 is 0.22.


What if we do not account for censored data? i.e., we eliminate trials where frogs did not respond to simulated intruder.


### Example 2: Christmas tree worm re-emergence after a simulated predator attack
These data come from Pezner et al. 2017 https://academic.oup.com/beheco/article/28/1/154/2453511. They tested the consistency of hiding time (latency to re-emerge from the hole) within and across days, and the impact of social environment. They tested 30 worms, each received 4 trials within a day and 4 days of sampling for a total of 16 trials per worm. Censored data are not explicitly stated, but there are 5 NA values from 2 individuals that we here assume are censored data (~1% of data). In the original paper, the authors log-transformed the hiding time variable, used a linear mixed model to get variance estimates, then hand-calculated repeatability.

```{r E2, echo=F}
## Load the data
ctw = read.csv("CTWemergence.csv")
# "HT" variable indicates hiding time, or the latency to emerge; "Whorls" is a visual indicator of age

# 2 individuals have NA values, but it is not explained why. 
# I'll assume these are censored (the worm didn't emerge in the trial time) and give ceiling value of one unit after other highest value
ctw$event = ifelse(is.na(ctw$HT),0,1)
ctw$HT[which(is.na(ctw$HT))]<- 375

## Explode the data
# decide on the intervals
psych::describe(ctw$HT)
ctw_int = survSplit(Surv(HT,event) ~ Whorls + Trial_Total + Worm_ID, data = ctw, 
                    cut = c(50,100,150,200,250,300,350,400), start = "tstart",end = "tstop")

## Cox model and ICC calculation
ctw.cox.int = coxme(Surv(tstart,tstop, event)~Whorls + (1|Worm_ID), data=ctw_int)

var <- VarCorr(ctw.cox.int)$Worm_ID[[1]]
var/(var + pi^2/6) #0.33
# Original paper finds across day hiding time repeatability is 0.42
```



### Example 3: Repeatability of distance to cache a seed in smalll mammals 
Brehm et al. 2019 (https://onlinelibrary.wiley.com/doi/full/10.1111/ele.13324) evaluated seed caching behavior in relation to multiple personality traits and habitat characteristics. They offered artificial seeds for small mammals to cache that had reflective flags attached so that the cached seeds could be relocated and the distance from the food platform could be measured. The data include 31 unique deer mice that cached between 1-12 seeds (mean = 3.31 &pm; 0.5). Understandably, it can be hard to relocate the cached seeds and so 35% of the caching distances were censored (seeds lost to follow up).

```{r E3, echo = F}
## Load the data
setwd("/Users/kelseymccune/Documents/GitHub/Time-to-Event_Repeatability/data")
data<-read.csv("data_seed_pers.csv")
pm<-subset(data, SPP=="PM") # only one species

pmdistmov<-subset(pm,REMOVE==1) # distance the seed is dispersed, only looking at seeds that were removed from the feeding platform
pmdistmov<-subset(pmdistmov, CONS!=1) # remove rows where the seed was consumed close by the feeding platform
pmdistmov$RECOVERED..Y.N.[which(pmdistmov$DIST..MOVED==15)]<-"Y" # one row seems to indicate the cached seed was found 15m from the feeding platform, but the categorical variable for whether it was removed is an NA 
table(pmdistmov$RECOVERED..Y.N.) # how many cached seeds did they recover (i.e., how much censored data is there?)
# 35% of data are censored
dist = pmdistmov[-which(pmdistmov$ID == "UNK"),c(1,5,6,14,17)] #simplify data frame
# the Recovered column is analogous to the event variable in survival analysis. Modify it to be an integer
dist$event = ifelse(dist$RECOVERED..Y.N.== "Y",1,0)
dist$event = ifelse(is.na(dist$event),0,dist$event)
dist$DIST..MOVED[which(is.na(dist$DIST..MOVED))]<-1038 # give ceiling value to NAs
dist.cox = coxme(Surv(DIST..MOVED, event) ~ TRT + (1|ID), data=dist)
summary(dist.cox)
coxme_pval(dist.cox,dist,boot=100)
coxme_icc_ci(dist.cox) # lower bound of CI is NA because ICC is small (0.05)?


## Explode the data
# Create intervals based on the number of events in each interval. Here, 25% of the data are in each of 4 intervals.
quantile(dist$DIST..MOVED, probs = seq(0,1,0.25),na.rm=T)

psych::describe(dist$DIST..MOVED)

dist_int = survSplit(Surv(DIST..MOVED, event) ~ ID, data = dist, 
                     cut = c(50,146,331.5), start = "tstart",end = "tstop")

## Cox model and ICC calculation
dist.cox.int = coxme(Surv(tstart,tstop, event) ~ 1 + (1|ID), data=dist_int)
var <- VarCorr(dist.cox.int)$ID[[1]] 
var/(var + pi^2/6) # 0.05
# Original paper did not run this particular analysis.
```

### Data and code for Case Study in manuscript

```{r Case Study, echo = F}

#Latency to solve a door on a puzzle box
jsolv = read.csv("jaySolveData.csv")
jsolv = jsolv[,c(2:6,9)]
colnames(jsolv)[6] = "Time"
jsolv$olre = factor(1:68)

solv.su = coxme(Surv(Time, Solve)~Treatment + (1|ID), data=jsolv)
summary(solv.su) 
coxme_pval(solv.su,jsolv,boot = 100)
coxme_icc_ci(solv.su) # adjusted ICC

solv.su2 = coxme(Surv(Time,Solve) ~ 1 + (1|ID), data = jsolv)
summary(solv.su2) 
coxme_pval(solv.su2,jsolv,boot = 100)
coxme_icc_ci(solv.su2) # unadjusted ICC

```

## Simulations (draft)

We conducted a small simulation study to examine the relationship of model estimates and ICC values derived from four different models: (1) a Cox proportional hazards model with a normal distribution of the random effect using `coxme` function in the `coxme` package, (2) a Cox proportional hazards model with a normal distribution of the random effect using `coxph` from the `survival` package, (3) a Cox proportional hazards model with a gamma distribution of the random effect using using `coxph` from the `survival` package, and (4) a binomial generalized linear mixed-effects model with a clog-log link using the `glmer` function from the `lme4` package. 

We simulated survival data for $n=1000$ observations and $n_{cluster}=100$ the number of clusters (to be $n_{cluster}=10$ (i.e. individuals). We simulated data given three different values for the random effect variance $\sigma^2_{\alpha}=1, 2, 3$ (frailty variance), two levels of censoring $c= 0, 0.15$ and two time interval splitting numbers $int\_n = (2, 4)$. We assumed a model with a single covariate (sex) as described in equation (xxx) in the main text. We set the true value of the covariate beta parameter to be $\beta_{sex}=0.5$.


A total of 1($n$) $\times$ 1($n_{cluster}$) $\times$ 3($\sigma^2_{f}$) $\times$ 2(censoring) $\times$ 2(interval) $=$ 12 conditions were examined. For each of these conditions, we simulated 1000 data sets and 1000 corresponding 'exploded' data sets.

The simulation study was conducted with R (R Core Team, 2024) and using the computational cluster Katana at UNSW Sydney (UNSW, 2024). 


## References

Bates, D., Maechler, M., Bolker, B., & Walker, S. (2015). Fitting linear mixed-effects models using lme4. *Journal of Statistical Software, 67*(1), 1-48. <https://doi.org/10.18637/jss.v067.i01>

R Core Team. (2024). *R: A language and environment for statistical computing*. R Foundation for Statistical Computing. <https://www.R-project.org/>

Therneau, T. M. (2024). *A package for survival analysis in R* (R package version 3.5-8). <https://CRAN.R-project.org/package=survival>

Therneau, T. M. (2024). *coxme: Mixed effects Cox models* (R package version 2.2-20). <https://CRAN.R-project.org/package=coxme>

Therneau, T. M., & Grambsch, P. M. (2000). *Modeling survival data: Extending the Cox model*. Springer. ISBN 0-387-98784-3
